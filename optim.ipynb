{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## optim.py\n",
    "\n",
    "#### Based on: tensorflow, numpy, copy, inspect\n",
    "\n",
    "#### Why Tensorflow?\n",
    "\n",
    "Tensorflow supports symbol computation well like Automatic derivation and the program\n",
    "could be excuted with GPU, which will save our time.\n",
    "\n",
    "#### dogleg(p_u, p_b, delta, tau = 2)\n",
    "The Dogleg method to solve the subproblems of trust region method\n",
    "\n",
    "#### getGrad(f, x_value)\n",
    "Get the gradient of function f with *tf.gradients()*  <br />\n",
    "<code>\n",
    "f= lambda x:100*(x[1]-x[0]**2)**2 + (1-x[0])**2\n",
    "x_value = [1.0,2.0]\n",
    "f_gradients = getGrad(f, x_value)\n",
    "<code/>\n",
    "    \n",
    "#### getHess(f, x_value)\n",
    "Get the Hessian matrix of f with *tf.hessian*\n",
    "\n",
    "#### TrustRegion_dogleg(f, delta = 0.5, eta = 0, *x_0, tolerance= 0.0001)\n",
    "Trust region method with subproblems solved by the Dogleg method\n",
    "\n",
    "#### ExactLineSearch_quadratic(f, x_k, p_k)\n",
    "Exact line search method when the target function is quadratic\n",
    "\n",
    "#### QuasiNewton(f, *x_0,  HUpdateMethod = 'BFGS', LineSearch = ExactLineSearch_quadratic, tolerance = 0.0001)\n",
    "quasi-Newton method\n",
    "\n",
    "#### PenaltySimple(f, c_eq, c_leq, epsilon)\n",
    "f is the target function, c_eq is a list contains equation constraints,\n",
    "c_leq is  a list contains unequal constrains, epsilon is the terminal parameter\n",
    "these functions could be function name or anonymous functions, which defined by 'lambda'\n",
    "The subproblem is solved by Newton Method, but it will be modified in the future because sometimes it's hard to compute the inverse matrix of Hessian matrix.\n",
    "\n",
    "### Example\n",
    "#### Demo 1:trust region method with subproblems solved by the Dogleg method\n",
    "<code>\n",
    "f = lambda x:100*(x[1]-x[0]**2)**2 + (1-x[0])**2\n",
    "f.paraLength = 2    ## 这一步不可缺少\n",
    "x_k, f_k = TrustRegion_dogleg(f, delta = 10)\n",
    "<code/>\n",
    "    \n",
    "#### Demo 2:quasi-Newton method demo\n",
    "<code>\n",
    "print('Demo 2:quasi-Newton method demo')\n",
    "f = lambda x:x[0]**2 + 2 * x[1]**2\n",
    "f.paraLength = 2\n",
    "x_0 = np.array([1, 1])\n",
    "x_k, f_k = QuasiNewton(f, x_0)\n",
    "<code/>\n",
    "    \n",
    "#### Demo 3:penalty function method demo\n",
    "<code>\n",
    "print('Demo 3:penalty function method demo')\n",
    "f = lambda x:x[0] + x[1]\n",
    "f.paraLength = 2\n",
    "c_eq = [lambda x:x[0]**2 + x[1]**2 - 2]\n",
    "c_leq = []\n",
    "x_k, f_k = PenaltySimple(f, c_eq, c_leq, [-3,-4])\n",
    "<code/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Demo 1:trust region method with subproblems solved by the Dogleg method\n",
      "H_k\n",
      "[[  2.   0.]\n",
      " [  0. 200.]]\n",
      "x_0\n",
      "[1. 0.]\n",
      "f_0 = 100.000000\n",
      "tolerance_0 = 2.000000\n",
      "The 1 iteration...\n",
      "H_k\n",
      "[[1202. -400.]\n",
      " [-400.  200.]]\n",
      "x_1\n",
      "[0.99999988 0.99999988]\n",
      "f_1 = 0.000000\n",
      "tolerance_1 = 447.213593\n",
      "The 2 iteration...\n",
      "H_k\n",
      "[[ 801.9997  -399.99994]\n",
      " [-399.99994  200.     ]]\n",
      "x_2\n",
      "[1. 1.]\n",
      "f_2 = 0.000000\n",
      "tolerance_2 = 0.000054\n",
      "The 3 iteration...\n",
      "After 3 times iteration, the Minimum point is:\n",
      "[1. 1.]\n",
      "and the Minimum value is 0.000000\n",
      "Demo 2:quasi-Newton method demo\n",
      "------\n",
      "[[1]\n",
      " [1]]\n",
      "The 1 iteration...\n",
      "a_0\n",
      "[[0.27777778]]\n",
      "x_1:\n",
      "[[ 0.44444444]\n",
      " [-0.11111111]]\n",
      "error = 0.993808\n",
      "The 2 iteration...\n",
      "a_0\n",
      "[[0.44999996]]\n",
      "x_2:\n",
      "[[-3.31136918e-09]\n",
      " [-6.62273836e-09]]\n",
      "error = 0.000000\n",
      "After 2 iteration, the minimum point = \n",
      "[[-3.31136918e-09]\n",
      " [-6.62273836e-09]]\n",
      "And the minimum value of f = \n",
      "9.868649254833501e-17\n",
      "Demo 3:penalty function method demo\n",
      "The 1th iteration...\n",
      "grad_norm = 0.680579\n",
      "grad_norm = 0.077829\n",
      "grad_norm = 0.002061\n",
      "grad_norm = 0.000002\n",
      "x_1\n",
      "[-2.46425074 -2.46425383]\n",
      "error = 10.145080\n",
      "The 2th iteration...\n",
      "grad_norm = 3.255242\n",
      "grad_norm = 0.612440\n",
      "grad_norm = 0.045789\n",
      "grad_norm = 0.000337\n",
      "x_2\n",
      "[-1.38047194 -1.38047198]\n",
      "error = 1.811406\n",
      "The 3th iteration...\n",
      "grad_norm = 2.512873\n",
      "grad_norm = 0.220474\n",
      "grad_norm = 0.002364\n",
      "grad_norm = 0.000001\n",
      "x_3\n",
      "[-1.05745374 -1.05745381]\n",
      "error = 0.236417\n",
      "The 4th iteration...\n",
      "grad_norm = 0.806962\n",
      "grad_norm = 0.004120\n",
      "grad_norm = 0.000010\n",
      "x_4\n",
      "[-1.00619236 -1.0061924 ]\n",
      "error = 0.024846\n",
      "The 5th iteration...\n",
      "grad_norm = 0.103955\n",
      "grad_norm = 0.000029\n",
      "x_5\n",
      "[-1.00062439 -1.00062436]\n",
      "error = 0.002498\n",
      "The 6th iteration...\n",
      "grad_norm = 0.011451\n",
      "grad_norm = 0.000689\n",
      "x_6\n",
      "[-1.00006244 -1.0000625 ]\n",
      "error = 0.000250\n",
      "After 6 iteration, the minimum point = \n",
      "[-1.00006244 -1.0000625 ]\n",
      "the minimum value = -2.000125\n",
      "c_i\n",
      "[0.00024986267]\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python  \n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "'''\n",
    "An implementation of Algorithms in numerical optimization\n",
    "\n",
    "TrustRegion_dogleg:trust region method with subproblems\n",
    "solved by the Dogleg method\n",
    "\n",
    "SteepestDescent:Steepest Descent method\n",
    "\n",
    "ConjugateGradient:Conjugate Gradient Method\n",
    "\n",
    "Newton: Newton's method\n",
    "\n",
    "QuasiNewton: quasi-Newton method\n",
    "\n",
    "PenaltySimple: penalty function method\n",
    "\n",
    "'''\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from inspect import isfunction\n",
    "import copy\n",
    "\n",
    "def dogleg(p_u, p_b, delta, tau = 2):\n",
    "    p_u2 = np.linalg.norm(p_u, 2)**2\n",
    "    p_b2 = np.linalg.norm(p_b, 2)**2\n",
    "    p_ub2 = np.linalg.norm(p_b-p_u, 2)**2\n",
    "    if p_u2 > delta**2:\n",
    "        tau = delta / np.linalg.norm(p_u,2)\n",
    "    elif (p_b2 > delta**2) and (p_u2 <= delta**2):\n",
    "        tau = np.sqrt((delta**2 - p_u2)/(p_ub2))+1\n",
    "    if (tau >= 0)and(tau <= 1):\n",
    "        p_k = tau * p_u\n",
    "    elif (tau >= 1)and(tau <= 2):\n",
    "        p_k = p_u + (tau - 1)*(p_b - p_u)\n",
    "    return p_k\n",
    "\n",
    "def getGrad(f, x_value):\n",
    "    x = tf.placeholder(tf.float32, shape=len(x_value) )\n",
    "    f_grad = tf.gradients(f(x), x)\n",
    "    sess = tf.Session()  \n",
    "    f_g = sess.run(f_grad, feed_dict = {x:x_value})\n",
    "    f_g_value = f_g[0]\n",
    "    return f_g_value\n",
    "\n",
    "def getHess(f, x_value):\n",
    "    x = tf.placeholder(tf.float32, shape=len(x_value) )  \n",
    "    f_grad = tf.hessians(f(x), x)\n",
    "    sess = tf.Session()  \n",
    "    f_g = sess.run(f_grad, feed_dict = {x:x_value})\n",
    "    f_g_value = f_g[0]\n",
    "    return f_g_value\n",
    "\n",
    "def ExactLineSearch_quadratic(f, x_k, p_k):\n",
    "    ## you can use this Exact Line search only when f is a quadratic function\n",
    "    f_grad = getGrad(f, x_k)\n",
    "    f_hess = getHess(f, x_k)\n",
    "    f_grad = np.mat(f_grad).T\n",
    "    f_hess = np.mat(f_hess)\n",
    "    alpha_k = (p_k.T * (-f_grad)) / (p_k.T * f_hess * p_k)\n",
    "    return alpha_k\n",
    "\n",
    "\n",
    "def QuasiNewton(f, *x_0,  HUpdateMethod = 'BFGS', LineSearch = ExactLineSearch_quadratic, tolerance = 0.0001):\n",
    "    if not hasattr(f, \"paraLength\"):\n",
    "        raise Exception(\"请确保目标函数f定义了f.paraLength属性, 为输入向量长度, \\\n",
    "              即\\\"f.paraLength = 变量个数 \\\" \")\n",
    "    assert isfunction(f)\n",
    "    input_size  = f.paraLength\n",
    "    # 初始化x_0\n",
    "    if len(x_0) != 0:\n",
    "        x_0 = np.mat(x_0[0]).T\n",
    "    else:\n",
    "        x_0 = np.mat(np.zeros((input_size,1))).T\n",
    "    H_0 = np.mat(np.eye(input_size))\n",
    "    print('------')\n",
    "    print(x_0)\n",
    "    g_0 = getGrad(f, (x_0.T).tolist()[0])\n",
    "    g_0 = np.mat(g_0).T\n",
    "    LSfun = LineSearch\n",
    "    ## H_k update function 这里采用占位符实际上起到了一般函数的作用\n",
    "    s_k = tf.placeholder(tf.float32, shape=np.shape(x_0))\n",
    "    y_k = tf.placeholder(tf.float32, shape=np.shape(x_0))\n",
    "    H_k = tf.placeholder(tf.float32, shape=(input_size, input_size)) \n",
    "    I_mat = np.eye(input_size)\n",
    "    divider = tf.matmul(tf.transpose(s_k), y_k)\n",
    "    update_3 = tf.matmul(s_k, tf.transpose(s_k))/divider\n",
    "    if HUpdateMethod == 'BFGS':     \n",
    "        update_1 = I_mat - tf.matmul(s_k, tf.transpose(y_k))/divider\n",
    "        update_2 = I_mat - tf.matmul(y_k, tf.transpose(s_k))/divider\n",
    "        H_update = tf.matmul(tf.matmul(update_1, H_k), update_2) + update_3\n",
    "    elif HUpdateMethod == 'DFP':\n",
    "        update_1 = tf.matmul(tfmatmul(tf.matmul(H_k, y_k), tf.transpose(y_k)), H_k)\n",
    "        update_2 = tf.matmul(tf.matmul(tf.transpose(y_k), H_k), y_k)\n",
    "        H_update = H_k + update_3 - update_1/update_2\n",
    "        \n",
    "    sess = tf.Session()\n",
    "    k_num = 1\n",
    "    while np.linalg.norm(g_0,2) > tolerance: \n",
    "        print('The %d iteration...'% (k_num))\n",
    "        p_0 = - np.dot(H_0, g_0)\n",
    "        a_0 = LSfun(f, (x_0.T).tolist()[0], p_0)\n",
    "        print('a_0')\n",
    "        print(a_0)\n",
    "        x_1 = x_0 + np.dot(p_0, a_0)\n",
    "        g_1 = np.mat(getGrad(f, (x_1.T).tolist()[0])).T\n",
    "        s_0 = x_1 - x_0\n",
    "        y_0 = g_1 - g_0\n",
    "        H_1 = sess.run(H_update, feed_dict = {s_k:s_0, y_k:y_0, H_k:H_0})\n",
    "        # for the next iteration\n",
    "        x_0 = copy.deepcopy(x_1)\n",
    "        g_0 = copy.deepcopy(g_1)\n",
    "        H_0 = copy.deepcopy(H_1)\n",
    "        print('x_%d:'%(k_num))\n",
    "        print(x_0)\n",
    "        print('error = %f'%(np.linalg.norm(g_0,2)))\n",
    "        k_num += 1\n",
    "        \n",
    "    print('After %d iteration, the minimum point = ' % (k_num-1))\n",
    "    print(x_0)\n",
    "    print('And the minimum value of f = ')\n",
    "    print(f((x_0.T).tolist()[0]))\n",
    "    return x_0, f((x_0.T).tolist()[0] )\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "def TrustRegion_dogleg(f, delta = 0.5, eta = 0, *x_0, tolerance= 0.0001):\n",
    "    if not hasattr(f, \"paraLength\"):\n",
    "        raise Exception(\"请确保目标函数f定义了f.paraLength属性, \\\n",
    "              为输入向量长度, 即\\\"f.paraLength = 变量个数\\\" \")\n",
    "    assert delta > 0\n",
    "    assert isfunction(f)\n",
    "    input_size  = f.paraLength\n",
    "    # 初始化x_0\n",
    "    if len(x_0) != 0:\n",
    "        pass\n",
    "    else:\n",
    "        x_0 = np.zeros(input_size)*0.05\n",
    "    delta_hat = 2*delta\n",
    "    x_k = copy.deepcopy(x_0)\n",
    "    delta_k = copy.deepcopy(delta)\n",
    "    g_k = getGrad(f, x_k) \n",
    "    k_num = 0\n",
    "    while np.linalg.norm(g_k, 2) > tolerance:\n",
    "        g_k = getGrad(f, x_k) \n",
    "#         print('g_%d:'%(k_num))\n",
    "#         print(g_k)\n",
    "        g_k = np.mat(g_k).T\n",
    "        g_k_square = tf.pow(tf.norm(g_k, 2), 2)\n",
    "        ## 注意这里把nump array转化为tf.matrix       \n",
    "        H_k = np.mat(getHess(f, x_k))\n",
    "#         print('H_%d:'%(k_num))\n",
    "#         print(H_k)\n",
    "        print('H_k')\n",
    "        print(H_k)\n",
    "        denom = tf.matmul(tf.matmul(g_k.T, H_k), g_k)\n",
    "        p_u = - g_k * g_k_square /denom\n",
    "        sess = tf.Session()\n",
    "        p_u = sess.run(p_u)\n",
    "        p_b = - tf.matmul(tf.matrix_inverse(H_k), g_k)\n",
    "        sess = tf.Session()\n",
    "        p_b = sess.run(p_b)\n",
    "#         print('p_u and p_b')\n",
    "#         print(p_u)\n",
    "#         print(p_b)\n",
    "        p_k = dogleg(p_u, p_b, delta_k)\n",
    "#         print('p_%d'% (k_num))\n",
    "#         print(p_k)\n",
    "        p_mat = np.mat(p_k)\n",
    "#         print(g_mat.T)\n",
    "#         print(p_mat)\n",
    "        pred = tf.matmul(g_k.T, p_mat)[0][0] + \\\n",
    "                1/2 * tf.matmul(tf.matmul(p_mat.T, H_k), p_mat)[0][0]\n",
    "        #pred = np.dot(g_mat.T, p_mat) + \\\n",
    "                #1/2 * np.dot(np.dot(p_mat.T, H_k), p_mat)\n",
    "        p_k = p_k.T[0]\n",
    "        ared = f(x_k + p_k) - f(x_k)\n",
    "        sess  = tf.Session()\n",
    "        pred = sess.run(pred)\n",
    "#         print('pred and ared')\n",
    "#         print(pred)\n",
    "#         print(ared)\n",
    "        rho_k = abs(ared / pred)\n",
    "#         print('rho_%d'%(k_num))\n",
    "#         print(rho_k)\n",
    "        if rho_k < 1/4:\n",
    "            delta_k = delta_k * 1/4\n",
    "        else:\n",
    "            if rho_k > 3/4 and np.linalg.norm(p_k, 2) == delta_k:\n",
    "                delta_k = min(2*delta_k, delta_hat)\n",
    "        if rho_k > eta:\n",
    "            x_k = x_k + p_k\n",
    "        print('x_%d' % (k_num))\n",
    "        print(x_k)\n",
    "        print('f_%d = %f'% (k_num, f(x_k)))\n",
    "        print('tolerance_%d = %f' %(k_num, np.linalg.norm(g_k, 2))) \n",
    "        k_num += 1\n",
    "        print('The %d iteration...' % (k_num))\n",
    "    print('After %d times iteration, the Minimum point is:'%(k_num))\n",
    "    print(x_k)\n",
    "    print('and the Minimum value is %f' %(f(x_k)))\n",
    "    return x_k, f(x_k)\n",
    "\n",
    "\n",
    "def PenaltySimple(f, c_eq, c_leq, *x_0, sigma = 0.01, alpha = 2, norm = 2, epsilon = 0.001):\n",
    "    '''\n",
    "    f is the target function, c_eq is a list contains equation constraints,\n",
    "    c_leq is  a list contains unequal constrains, epsilon is the terminal parameter\n",
    "    these functions could be function name or anonymous functions, which defined by 'lambda'\n",
    "    '''\n",
    "    #c_leq_new = []\n",
    "    if not hasattr(f, \"paraLength\"):\n",
    "        raise Exception(\"请确保目标函数f定义了f.paraLength属性, \\\n",
    "              为输入向量长度, 即\\\"f.paraLength = 变量个数\\\" \")\n",
    "    assert isfunction(f)\n",
    "    input_size  = f.paraLength\n",
    "    # 初始化x_0\n",
    "    if len(x_0) != 0:\n",
    "        x_0 = x_0[0]\n",
    "    else:\n",
    "        x_0 = np.zeros(input_size)\n",
    "        \n",
    "    x = tf.placeholder(tf.float32, shape=np.shape(x_0))\n",
    "    sigma_tf = tf.placeholder(tf.float32)\n",
    "    c_eq_new = []\n",
    "    c_leq_new = []\n",
    "    norm_tf = norm\n",
    "    alpha_tf= alpha\n",
    "    for fun in c_eq:\n",
    "        c_eq_new.append(fun(x))\n",
    "    for fun in c_leq:\n",
    "        c_leq_new.append(tf.minimum(tf.constant(0.0), fun(x)))\n",
    "    #c_leq_new = list(map(lambda fun:(lambda x:tf.minimum(0, fun(x))), c_leq))\n",
    "    c_eq = c_eq_new + c_leq_new\n",
    "    p_fun = f(x) + sigma_tf * tf.pow(tf.norm(c_eq, norm_tf), alpha_tf)\n",
    "    c_xsigma_norm = 1000\n",
    "    sess = tf.Session()\n",
    "    k_num = 0\n",
    "    while c_xsigma_norm > epsilon:\n",
    "        ## 梯度下降法求罚函数最小值点\n",
    "        print('The %dth iteration...'%(k_num+1))\n",
    "        grad_inside = tf.gradients(p_fun, x)\n",
    "        hess_inverse = tf.matrix_inverse(tf.hessians(p_fun,x))\n",
    "        grad_norm = tf.norm(grad_inside, 2)\n",
    "        grad_inside = sess.run(grad_inside, feed_dict = {x:x_0, sigma_tf:sigma})[0]\n",
    "        hess_inverse = sess.run(hess_inverse , feed_dict = {x:x_0, sigma_tf:sigma})[0]\n",
    "        grad_norm = sess.run(grad_norm, feed_dict = {x:x_0,sigma_tf:sigma})\n",
    "        while grad_norm > 0.001:\n",
    "            x_0 = x_0 - np.array((hess_inverse * np.mat(grad_inside).T).T.tolist())[0]\n",
    "            grad_inside = tf.gradients(p_fun, x)\n",
    "            hess_inverse = tf.matrix_inverse(tf.hessians(p_fun,x))\n",
    "            grad_norm = tf.norm(grad_inside, 2)\n",
    "            grad_inside = sess.run(grad_inside, feed_dict = {x:x_0, sigma_tf:sigma})[0]\n",
    "            hess_inverse = sess.run(hess_inverse , feed_dict = {x:x_0, sigma_tf:sigma})[0]\n",
    "            grad_norm = sess.run(grad_norm, feed_dict = {x:x_0,sigma_tf:sigma})\n",
    "            print('grad_norm = %f'%(grad_norm))\n",
    "        xsigma = copy.deepcopy(x_0)\n",
    "        print('x_%d'%(k_num+1))\n",
    "        print(x_0)\n",
    "        c_xsigma_norm = sess.run(tf.norm(c_eq), feed_dict = {x:xsigma})\n",
    "        sigma = 10*sigma\n",
    "        k_num += 1\n",
    "        print('error = %f'% (c_xsigma_norm))\n",
    "    print('After %d iteration, the minimum point = '%(k_num))    \n",
    "    print(xsigma)\n",
    "    print('the minimum value = %f' %(f(xsigma)))\n",
    "    print('c_i')\n",
    "    print(sess.run(c_eq, feed_dict = {x:xsigma}))\n",
    "    #p_fun = tf.norm(c_eq,2)\n",
    "    #P_fun  = lambda x: (f(x) + sigma * \n",
    "    #         (np.linalg.norm(list(map(lambda fun:fun(x), c_eq)), norm) ** alpha))\n",
    "    x_k = xsigma\n",
    "    f_k = f(xsigma)\n",
    "    return x_k, f_k\n",
    "    \n",
    "    \n",
    "def main():    \n",
    "    ## Demo 1:trust region method with subproblems solved by the Dogleg method\n",
    "    print('Demo 1:trust region method with subproblems solved by the Dogleg method')\n",
    "    f = lambda x:100*(x[1]-x[0]**2)**2 + (1-x[0])**2\n",
    "    f.paraLength = 2    ## 这一步不可缺少\n",
    "#     print(f.paraLength)\n",
    "    x_k, f_k = TrustRegion_dogleg(f, delta = 10)\n",
    "    \n",
    "    ## Demo 2:quasi-Newton method demo\n",
    "    print('Demo 2:quasi-Newton method demo')\n",
    "    f = lambda x:x[0]**2 + 2 * x[1]**2\n",
    "    f.paraLength = 2\n",
    "    x_0 = np.array([1, 1])\n",
    "    x_k, f_k = QuasiNewton(f, x_0)\n",
    "    \n",
    "    ## Demo 3:penalty function method demo\n",
    "    print('Demo 3:penalty function method demo')\n",
    "    f = lambda x:x[0] + x[1]\n",
    "    f.paraLength = 2\n",
    "    c_eq = [lambda x:x[0]**2 + x[1]**2 - 2]\n",
    "    c_leq = []\n",
    "    x_k, f_k = PenaltySimple(f, c_eq, c_leq, [-3,-4])\n",
    "    #if len(c_leq) > 0:        \n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('x',)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-118-de11d0f373c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mf_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mf_grad_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf_grad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf_grad_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1136\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1137\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1138\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1353\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1355\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1356\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1357\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1359\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1360\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1361\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1362\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1363\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1330\u001b[0m                 run_metadata):\n\u001b[1;32m   1331\u001b[0m       \u001b[0;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1332\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1333\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_extend_graph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1390\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m           tf_session.TF_ExtendGraph(self._session,\n\u001b[0;32m-> 1392\u001b[0;31m                                     graph_def.SerializeToString(), status)\n\u001b[0m\u001b[1;32m   1393\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_opened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0.]\n",
      "[1.0]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0.]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python36(tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
